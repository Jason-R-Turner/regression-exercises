{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd99c09-90bd-4f0e-9149-9ecdd5c452b8",
   "metadata": {},
   "source": [
    "2. Using your acquired Zillow data, walk through the summarization and cleaning steps in your wrangle.ipynb file like we did above. You may handle the missing values however you feel is appropriate and meaninful; remember to document your process and decisions using markdown and code commenting where helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c0d83b-0345-47f1-b053-1926e63dcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import env\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92b1971-ee76-4e3e-bee7-c717a4c07c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection(db, user=env.user, host=env.host, password=env.password):\n",
    "    '''\n",
    "    Function allows user to access Codeup database using their own \n",
    "    credentials stored in  their env.py file\n",
    "    '''\n",
    "    \n",
    "# Returns with correct address/password combinat to access the database\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27921c18-4f26-4eb0-af18-06d48fa196fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_zillow_data():\n",
    "    '''\n",
    "    SQL query that joins the customers table with, contract, payment, and \\n\n",
    "    internet service options\n",
    "    '''\n",
    "    \n",
    "# SQL query that joins three other tables to customer table\n",
    "    sql_query = '''\n",
    "                SELECT bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, fips FROM properties_2017\n",
    "                join propertylandusetype using (propertylandusetypeid)\n",
    "                where propertylandusedesc = \"Single Family Residential\"\n",
    "                '''\n",
    "# Read in DataFrame from Codeup db.\n",
    "    df = pd.read_sql(sql_query, get_connection('zillow'))\n",
    "    \n",
    "# Returns the called dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b540334c-c75d-4b90-8b79-3e9146ab018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zillow_data():\n",
    "    '''\n",
    "    Function allows user to access zillow_data from Codeup database and write it\\n\n",
    "    to a csv file then returns the dataframe.\n",
    "    '''\n",
    "    \n",
    "# if statement that checks if there's already a .csv file to use \n",
    "    if os.path.isfile('zillow.csv'):\n",
    "        \n",
    "# If csv file exists read in data from csv file.\n",
    "        df = pd.read_csv('zillow.csv', index_col=0)\n",
    "        \n",
    "# Alternative if no csv file found then\n",
    "    else:\n",
    "        \n",
    "# Read fresh data from db into a DataFrame\n",
    "        df = new_zillow_data()\n",
    "        \n",
    "# Cache data for local use\n",
    "        df.to_csv('zillow.csv')\n",
    "\n",
    "# Returns requested df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0d9037-8b78-46e3-ac69-a7e65aa02839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nulls(df):\n",
    "    '''\n",
    "    Gets rid of the rows with any null values and returns a new null-free df\n",
    "    '''\n",
    "    \n",
    "# drops the rows with any null values and returns a new null-free df\n",
    "    df = df.dropna()\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e6ae12-e01e-4729-872a-07285ed6eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_int(df):\n",
    "    '''\n",
    "    Converts our fips, bedrooms, calculatedfinishedsquarefeet, taxvaluedollarcnt, and yearbuilt from floats to integers\n",
    "    '''\n",
    "# converts our fips, bedrooms, calculatedfinishedsquarefeet, taxvaluedollarcnt, and yearbuilt from floats to integers\n",
    "    df[\"fips\"] = df[\"fips\"].astype(int)\n",
    "    df[\"yearbuilt\"] = df[\"yearbuilt\"].astype(int)\n",
    "    df[\"bedroomcnt\"] = df[\"bedroomcnt\"].astype(int)\n",
    "    df[\"taxvaluedollarcnt\"] = df[\"taxvaluedollarcnt\"].astype(int)\n",
    "    df[\"calculatedfinishedsquarefeet\"] = df[\"calculatedfinishedsquarefeet\"].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c78e8273-e407-4597-920b-a1a4510edb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_zillow(df):\n",
    "    '''\n",
    "    Groups our functions used to clean up our data into a single function for ease of use\n",
    "    '''\n",
    "    \n",
    "    df = handle_nulls(df)\n",
    "    df = float_to_int(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "576cd42d-c74b-47d5-89dc-0fb8c4695553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_zillow(df):\n",
    "    '''\n",
    "    Takes our df and splits it into train, validate, and test dfs for exploration, fitting, validation, and testing\n",
    "    '''\n",
    "    \n",
    "# splits the full data set 60/40 into train and test dataframes stratified \n",
    "# around taxvaluedollarcnt, the target variable, using the train_test_split function\n",
    "    train, test = train_test_split(df, \n",
    "                               train_size = 0.75, \n",
    "                               stratify = df.fips, \n",
    "                               random_state=2468)\n",
    "\n",
    "# splits the train dataframe 60/40 into the new train and validate dataframes\n",
    "# they're stratified around taxvaluedollarcnt again using the train_test_split function\n",
    "    train, validate = train_test_split(train,\n",
    "                                    train_size = 0.75,\n",
    "                                    stratify = train.fips,\n",
    "                                    random_state=2468)\n",
    "    \n",
    "# returns the three dataframes we'll use for training, validation, and testing\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90410179-1fbb-4bca-a77b-d436c0307b1f",
   "metadata": {},
   "source": [
    "3. Store all of the necessary functions to automate your process from acquiring the data to returning a cleaned dataframe witn no missing values in your wrangle.py file. Name your final function wrangle_zillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f9a3d2-bbdc-4fb4-9ac9-63df0d010ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrangle_zillow():\n",
    "    '''\n",
    "    Function that acquires zillow data using the new_zillow_data function and \n",
    "    caches it, as a csv file, if there isn't already a local copy\n",
    "    '''\n",
    "    df = get_zillow_data()\n",
    "    df = clean_zillow(df)\n",
    "    train, validate, test = split_zillow(df)\n",
    "    \n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e15e94-7a6f-4b6f-865b-d87152798639",
   "metadata": {},
   "source": [
    "5. Based on the work you've done, choose a scaling method for your dataset. Write a function within your prepare.py (wrangle.py for me) that accepts as input the train, validate, and test data splits, and returns the scaled versions of each. Be sure to only learn the parameters for scaling from your training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be0eea3-984c-4990-9779-331fa1cb91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_zillow(train, validate, test,\n",
    "                 cols_to_scale = ['bedroomcnt', 'bathroomcnt', 'calculatedfinishedsquarefeet', 'taxvaluedollarcnt']):\n",
    "    '''\n",
    "    Accepts train, valide, and test as inputs from split data then returns scaled versions for each one\n",
    "    '''\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = validate.copy()\n",
    "    test_scaled = test.copy()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    scaler.fit(train[cols_to_scale])\n",
    "    \n",
    "    train_scaled[cols_to_scale] = pd.DataFrame(scaler.transform(train[cols_to_scale]), columns=train[cols_to_scale].columns.values).set_index([train.index.values])\n",
    "                                                  \n",
    "    validate_scaled[cols_to_scale] = pd.DataFrame(scaler.transform(validate[cols_to_scale]), columns=validate[cols_to_scale].columns.values).set_index([validate.index.values])\n",
    "    \n",
    "    test_scaled[cols_to_scale] = pd.DataFrame(scaler.transform(test[cols_to_scale]), columns=test[cols_to_scale].columns.values).set_index([test.index.values])\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d47c5-02d9-4251-a4df-d997f28ceb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
